{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Testing.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/capitaineoblivious/Grab_AIforSEA/blob/master/Testing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sa7wx4lKRCuO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "outputId": "7f790b6b-9da8-4ed0-d623-681717f07dd6"
      },
      "source": [
        "!pip install python-geohash\n",
        "#!pip install pandas\n",
        "#!pip install tensorflow\n",
        "#!pip install numpy\n",
        "#!pip install matplotlib"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting python-geohash\n",
            "  Downloading https://files.pythonhosted.org/packages/9c/e2/1a3507af7c8f91f8a4975d651d4aeb6a846dfdf74713954186ade4205850/python-geohash-0.8.5.tar.gz\n",
            "Building wheels for collected packages: python-geohash\n",
            "  Building wheel for python-geohash (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/b5/64/5a/6a286481fc7c2a698d2f297d4c90af19946be430b23eba9a33\n",
            "Successfully built python-geohash\n",
            "Installing collected packages: python-geohash\n",
            "Successfully installed python-geohash-0.8.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "viFRLuIFQ0LZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c9afa191-883e-4956-ec06-5f6ec70d2588"
      },
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "\n",
        "import geohash\n",
        "\n",
        "import folium\n",
        "from folium import plugins\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "import tensorflow as tf\n",
        "tf.enable_eager_execution()\n",
        "\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  print('GPU not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZsownb6RfjV",
        "colab_type": "text"
      },
      "source": [
        "Please change the link below to use your data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rb-Vk5LGQ-Oz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "8bfc4dad-66fa-4017-f22e-fcee6bb1a5e0"
      },
      "source": [
        "dataset_link = 'https://s3-ap-southeast-1.amazonaws.com/grab-aiforsea-dataset/traffic-management.zip'\n",
        "df = pd.read_csv(dataset_link, compression='zip', header=0, sep=',', quotechar='\"')\n",
        "df.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>geohash6</th>\n",
              "      <th>day</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>demand</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>qp03wc</td>\n",
              "      <td>18</td>\n",
              "      <td>20:0</td>\n",
              "      <td>0.020072</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>qp03pn</td>\n",
              "      <td>10</td>\n",
              "      <td>14:30</td>\n",
              "      <td>0.024721</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>qp09sw</td>\n",
              "      <td>9</td>\n",
              "      <td>6:15</td>\n",
              "      <td>0.102821</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>qp0991</td>\n",
              "      <td>32</td>\n",
              "      <td>5:0</td>\n",
              "      <td>0.088755</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>qp090q</td>\n",
              "      <td>15</td>\n",
              "      <td>4:0</td>\n",
              "      <td>0.074468</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  geohash6  day timestamp    demand\n",
              "0   qp03wc   18      20:0  0.020072\n",
              "1   qp03pn   10     14:30  0.024721\n",
              "2   qp09sw    9      6:15  0.102821\n",
              "3   qp0991   32       5:0  0.088755\n",
              "4   qp090q   15       4:0  0.074468"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eURRFT9HSF8K",
        "colab_type": "text"
      },
      "source": [
        "We recover the scaling values from the set of geohashes used for the training process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VbVoR9vNR4uz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "std_lat=0.07292679591440783 \n",
        "mean_lat=-5.361328125  \n",
        "std_long=0.11412921417661685\n",
        "mean_long=90.780029296875\n",
        "\n",
        "geohashes = df.geohash6.unique().tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBcP3PjGSPCR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "eaa718ce-0d18-45bd-f17a-c7fe5136fe86"
      },
      "source": [
        "max_d = int(max(df.day))\n",
        "all_ts = []\n",
        "for d in range(1, max_d +1):\n",
        "    for h in range(0, 24):\n",
        "        for m in [0,15,30,45]:\n",
        "            ts = str(d).zfill(2) + '-' + str(h).zfill(2) + ':' + str(m).zfill(2)\n",
        "            all_ts.append(ts)\n",
        "\n",
        "print('The first timestamp of the data set is:', all_ts[0])\n",
        "print('The last timestamp of the data set is:', all_ts[-1])\n",
        "print('There are %d timestamps in the dataset' %(len(all_ts)))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The first timestamp of the data set is: 01-00:00\n",
            "The last timestamp of the data set is: 61-23:45\n",
            "There are 5856 timestamps in the dataset\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pO48mH14SdxN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def formatted(string):\n",
        "    hour, minute = string.split(':')\n",
        "    return hour.zfill(2) + \":\" + minute.zfill(2)\n",
        "\n",
        "def hour(string):\n",
        "    hour, minute = string.split(':')\n",
        "    return int(hour)\n",
        "\n",
        "df['hour'] = df['timestamp'].apply(hour)    \n",
        "df['timestamp'] = df.day.apply(lambda x: str(x).zfill(2)) + '-' + df['timestamp'].apply(formatted)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uxRhrI1uM7Tf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b97d9dd7-bc3a-45ec-c244-f088cc83917a"
      },
      "source": [
        "data = df.pivot(index='timestamp', columns='geohash6', values='demand')\n",
        "data = data.reindex(all_ts).fillna(0)\n",
        "\n",
        "Tmax = 14 * 24 * 4 # maximum 14 days input\n",
        "if len(data.index) > Tmax:\n",
        "    data = data.iloc[-Tmax:]\n",
        "data.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1344, 1329)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "333uZxaHgSRh",
        "colab_type": "text"
      },
      "source": [
        "We build the model inputs from the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p00nawXZgW_Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4479dd24-2e50-4956-dd14-3e88de3d2fe1"
      },
      "source": [
        "def generate_input(data):\n",
        "    \n",
        "    Tx, m = data.shape\n",
        "    X = np.zeros((m, Tx, 29)) # 29 features : demand, one hot vector of hours (24), long, lat, long2, lat2\n",
        "\n",
        "    count = 0\n",
        "    for ghash in data.columns:\n",
        "        sample = data[ghash]\n",
        "        ts = sample.iloc[:-5].index\n",
        "        sample = sample.iloc[:-5].values\n",
        "\n",
        "        lat, long = geohash.decode(ghash)\n",
        "        lat = (lat - mean_lat) / std_lat\n",
        "        long = (long - mean_long) / std_long\n",
        "\n",
        "        matrix = np.zeros((Tx, 29))\n",
        "        for j, s in enumerate(ts):\n",
        "            hour = int(s.split('-')[1].split(':')[0])\n",
        "            matrix[j, 0] = sample[j]\n",
        "            matrix[j, hour+1] = 1\n",
        "            matrix[j, 25:] = np.array([lat, long, lat**2, long**2])\n",
        "        X[count] = matrix\n",
        "        count +=1\n",
        "    return X\n",
        "\n",
        "A = generate_input(data)\n",
        "A.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1329, 1344, 29)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IYrRZ9D9i-1x",
        "colab_type": "text"
      },
      "source": [
        "We load the pretrained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNylseAjG0xH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "68417295-5a4a-489a-fb0f-5df62a224dd7"
      },
      "source": [
        "if tf.test.is_gpu_available():\n",
        "  print(' GPU acceleration available')\n",
        "  rnn = tf.keras.layers.CuDNNLSTM\n",
        "else:\n",
        "  print(' NO GPU detected')\n",
        "  rnn = tf.keras.layers.LSTM\n",
        "\n",
        "# define model where LSTM is also output layer\n",
        "\n",
        "def build_model(batch_size=16):\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(tf.keras.layers.BatchNormalization(input_shape=(None, 29),batch_size=batch_size))\n",
        "    model.add(rnn(256, return_sequences=True, stateful=True))\n",
        "    model.add(rnn(128, return_sequences=True, stateful=True))\n",
        "    model.add(rnn(64, return_sequences=True, stateful=True))\n",
        "    model.add(rnn(64, return_sequences=True, stateful=True))\n",
        "    model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "    return model\n",
        "\n",
        "model = build_model(batch_size=1)\n",
        "opt = tf.keras.optimizers.Adam(lr=0.015, beta_1=0.9, beta_2=0.999, decay=0.005)\n",
        "model.compile(optimizer=opt, loss='mean_squared_error')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " GPU acceleration available\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3W2mBMjiX_Ew",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        },
        "outputId": "15e91838-4691-487a-d45f-a59f1a756afe"
      },
      "source": [
        "! git clone https://github.com/capitaineoblivious/Grab_AIforSEA"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Grab_AIforSEA'...\n",
            "remote: Enumerating objects: 9, done.\u001b[K\n",
            "remote: Counting objects: 100% (9/9), done.\u001b[K\n",
            "remote: Compressing objects: 100% (7/7), done.\u001b[K\n",
            "remote: Total 9 (delta 1), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (9/9), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zXrSKlSEYFPU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3a3c2ab3-a4f1-4af5-8823-691fff6b682e"
      },
      "source": [
        "!ls Grab_AIforSEA/"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "my_model.h5  README.md\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yiKhev3AjOQj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "07972e3f-1d35-46b3-a04d-439862dd74d9"
      },
      "source": [
        "model.load_weights('Grab_AIforSEA/my_model.h5')\n",
        "model.summary()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "batch_normalization (BatchNo (1, None, 29)             116       \n",
            "_________________________________________________________________\n",
            "cu_dnnlstm (CuDNNLSTM)       (1, None, 256)            293888    \n",
            "_________________________________________________________________\n",
            "cu_dnnlstm_1 (CuDNNLSTM)     (1, None, 128)            197632    \n",
            "_________________________________________________________________\n",
            "cu_dnnlstm_2 (CuDNNLSTM)     (1, None, 64)             49664     \n",
            "_________________________________________________________________\n",
            "cu_dnnlstm_3 (CuDNNLSTM)     (1, None, 64)             33280     \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (1, None, 1)              65        \n",
            "=================================================================\n",
            "Total params: 574,645\n",
            "Trainable params: 574,587\n",
            "Non-trainable params: 58\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2QkcVimpiQtl",
        "colab_type": "text"
      },
      "source": [
        "We define the function that will predict the demand at time T+1 to T+5, given the history up to time T"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y88kczuMiduF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_predictions(input, model2):\n",
        "    seq = input.copy()\n",
        "    a, b, c = seq.shape\n",
        "    pred = np.zeros((a, b))\n",
        "    out = None\n",
        "    \n",
        "    model2.reset_states()\n",
        "\n",
        "    for i in range(b):\n",
        "        val = seq[:,i,:].reshape((a,1,c))\n",
        "        if i >= b-5:\n",
        "            val[:,0,0] = out\n",
        "        \n",
        "        pred[:,i] = val[:,0,0]\n",
        "        out = model2.predict(val)\n",
        "        out = tf.squeeze(out).numpy()\n",
        "\n",
        "    return pred"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OfUq_hXTQvPP",
        "colab_type": "text"
      },
      "source": [
        "The prediction phase takes in the data from 0 to T-5 and compares the predictions from T-5 to T with the expected values from T-5 to T\n",
        "We print the RMSE below. The whole computation might take a while depending on the size of the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nm6fJcbIpxM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = generate_input(data)\n",
        "a, b, c = X.shape\n",
        "predictions_dic = {}\n",
        "error_dic = {}\n",
        "pred = make_predictions(X[:,:,:], model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99V-1FCzS2_w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e25a9776-9491-4bff-d7e9-d334249d38c8"
      },
      "source": [
        "forecast = pred[:,-5:]\n",
        "target = X[:,-5:,0]\n",
        "\n",
        "rmse = np.mean(np.sqrt((forecast-target)**2))\n",
        "\n",
        "print(\"The RMSE is : %.4f\" %(rmse))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The RMSE is : 0.0246\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OYxmVEflTI6s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rmse"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0iaRPzggfkl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}